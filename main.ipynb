{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 37705,
          "sourceType": "datasetVersion",
          "datasetId": 29561
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Project1_2020205177",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "jessicali9530_celeba_dataset_path = kagglehub.dataset_download('jessicali9530/celeba-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "HesGPnIZm54O"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Member 1 ID: 2020205177\n",
        "Could not find another member as I finished the project really early and quickly. I am sorry for that."
      ],
      "metadata": {
        "id": "WkF7Jjbym54S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:50:43.942884Z",
          "iopub.execute_input": "2025-12-15T17:50:43.943511Z",
          "iopub.status.idle": "2025-12-15T17:50:43.94718Z",
          "shell.execute_reply.started": "2025-12-15T17:50:43.943486Z",
          "shell.execute_reply": "2025-12-15T17:50:43.94624Z"
        },
        "id": "6cbjFrC7m54T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_attr = pd.read_csv('/kaggle/input/celeba-dataset/list_attr_celeba.csv')\n",
        "df_attr.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:50:43.948525Z",
          "iopub.execute_input": "2025-12-15T17:50:43.948853Z",
          "iopub.status.idle": "2025-12-15T17:50:44.51626Z",
          "shell.execute_reply.started": "2025-12-15T17:50:43.948835Z",
          "shell.execute_reply": "2025-12-15T17:50:44.515554Z"
        },
        "id": "MRCmsSUIm54U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = pd.read_csv('/kaggle/input/celeba-dataset/list_eval_partition.csv')\n",
        "df_eval.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:50:44.516994Z",
          "iopub.execute_input": "2025-12-15T17:50:44.517262Z",
          "iopub.status.idle": "2025-12-15T17:50:44.616101Z",
          "shell.execute_reply.started": "2025-12-15T17:50:44.517238Z",
          "shell.execute_reply": "2025-12-15T17:50:44.615397Z"
        },
        "id": "dE2Nr9uam54U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#cloning STYLEGAN2 ADA repository\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
        "\n",
        "#change the current working directory to the cloned repository\n",
        "import os\n",
        "os.chdir('stylegan2-ada-pytorch')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:50:44.617624Z",
          "iopub.execute_input": "2025-12-15T17:50:44.618057Z",
          "iopub.status.idle": "2025-12-15T17:50:45.737774Z",
          "shell.execute_reply.started": "2025-12-15T17:50:44.618037Z",
          "shell.execute_reply": "2025-12-15T17:50:45.737019Z"
        },
        "id": "CjBcYYtHm54V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "#define the pretrained model URL and the local filename\n",
        "ffhq_url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl'\n",
        "pkl_file_name = 'ffhq.pkl'\n",
        "\n",
        "#download the file\n",
        "print(f\"Downloading {pkl_file_name}...\")\n",
        "response = requests.get(ffhq_url, stream=True)\n",
        "\n",
        "with open(pkl_file_name, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"Download complete.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:50:45.738778Z",
          "iopub.execute_input": "2025-12-15T17:50:45.739001Z",
          "iopub.status.idle": "2025-12-15T17:51:03.465236Z",
          "shell.execute_reply.started": "2025-12-15T17:50:45.738968Z",
          "shell.execute_reply": "2025-12-15T17:51:03.462961Z"
        },
        "id": "Jbnb16P6m54V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "#loading G_ema. This is the moving average generator, instead of a generator that\n",
        "#is stopped somewhere along the training steps\n",
        "print(\"Loading model...\")\n",
        "with open(pkl_file_name, 'rb') as f:\n",
        "    G = pickle.load(f)['G_ema'].cuda()  # Move to GPU"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.465833Z",
          "iopub.status.idle": "2025-12-15T17:51:03.466164Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.465971Z",
          "shell.execute_reply": "2025-12-15T17:51:03.465988Z"
        },
        "id": "n3eNd8l5m54W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying 10 random images, generated by random sampling vectors from z-space\n",
        "for i in range(10):\n",
        "    i+=1\n",
        "    #generating a random Z-space vector\n",
        "    #the tensor shape is important\n",
        "    seed = 123\n",
        "    z = torch.randn([1, G.z_dim], device='cuda')\n",
        "\n",
        "    #generating the image\n",
        "    #G() is a shortcut for G.synthesis(G.mapping(z, c))\n",
        "    #so we can just feed G with a z-vector and it will give us an image\n",
        "\n",
        "    img_tensor = G(z, None)\n",
        "\n",
        "    #to use PIL, we need to move the image to cpu\n",
        "    #print(img_tensor[0].shape)\n",
        "    img_numpy = img_tensor.cpu().numpy()[0]\n",
        "    #for debugging\n",
        "    #print(img_numpy.shape)\n",
        "    #print(\"TRANSPOSE:\")\n",
        "    #print(img_numpy.transpose(1,2,0).shape)\n",
        "\n",
        "    #the image that is generated by the model has pixel values of range -1 to 1.\n",
        "    #we want the range 0,255 as normal.\n",
        "    #also the tensor that we got is structured like C x H x W.\n",
        "    #we want H x W x C. so we transpose.\n",
        "\n",
        "    img_numpy = (img_numpy.transpose(1, 2, 0) * 127.5 + 128).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "    #creating the usable image\n",
        "\n",
        "    img = Image.fromarray(img_numpy, 'RGB')\n",
        "    img.save('generated_test_image.png')\n",
        "\n",
        "    print(\"Image generated successfully! (generated_test_image.png)\")\n",
        "    from IPython.display import display\n",
        "    display(img)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T18:42:58.020135Z",
          "iopub.execute_input": "2025-12-15T18:42:58.020723Z",
          "iopub.status.idle": "2025-12-15T18:43:05.165531Z",
          "shell.execute_reply.started": "2025-12-15T18:42:58.020696Z",
          "shell.execute_reply": "2025-12-15T18:43:05.164403Z"
        },
        "id": "jgZtf_YLm54W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the target column (I chose smiling attribute)\n",
        "df_attr['Smiling'] = (df_attr['Smiling'] > 0).copy().astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.468772Z",
          "iopub.status.idle": "2025-12-15T17:51:03.469014Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.4689Z",
          "shell.execute_reply": "2025-12-15T17:51:03.46891Z"
        },
        "id": "2lpwLYtkm54X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_attr.columns:\n",
        "    if col == 'image_id' or col == 'Smiling':\n",
        "        continue\n",
        "    else:\n",
        "        #copying so that df_attr stays the same, and notebook's integration is intact.\n",
        "        df_attr = df_attr.copy().drop(f'{col}', axis = 1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.46969Z",
          "iopub.status.idle": "2025-12-15T17:51:03.469963Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.469806Z",
          "shell.execute_reply": "2025-12-15T17:51:03.469821Z"
        },
        "id": "7iqTfhyCm54X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_attr\n",
        "y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.471991Z",
          "iopub.status.idle": "2025-12-15T17:51:03.472238Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.472115Z",
          "shell.execute_reply": "2025-12-15T17:51:03.472127Z"
        },
        "id": "awD3fBUjm54X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.473658Z",
          "iopub.status.idle": "2025-12-15T17:51:03.473957Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.473792Z",
          "shell.execute_reply": "2025-12-15T17:51:03.473807Z"
        },
        "id": "AtUCJrupm54X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#merging the eval df with y(target attribute) on image id.\n",
        "df_merged = pd.merge(y, df_eval, on = 'image_id')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.47498Z",
          "iopub.status.idle": "2025-12-15T17:51:03.47518Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.475084Z",
          "shell.execute_reply": "2025-12-15T17:51:03.475092Z"
        },
        "id": "qp9k2Oc4m54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.476776Z",
          "iopub.status.idle": "2025-12-15T17:51:03.477068Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.476923Z",
          "shell.execute_reply": "2025-12-15T17:51:03.476945Z"
        },
        "id": "FoeAzPl5m54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#the list_eval_partition.csv file in CelebA dataset has the format that partition\n",
        "#column can take values 0,1 or 2 and these correspond to train, validation, and test\n",
        "#splits respectively. Implementing that, using my merged_df:\n",
        "df_train = df_merged[df_merged['partition'] == 0].reset_index(drop = True)\n",
        "df_val = df_merged[df_merged['partition'] == 1].reset_index(drop = True)\n",
        "df_test = df_merged[df_merged['partition'] == 2].reset_index(drop = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.478068Z",
          "iopub.status.idle": "2025-12-15T17:51:03.478394Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.478217Z",
          "shell.execute_reply": "2025-12-15T17:51:03.478231Z"
        },
        "id": "xtW7nvjKm54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Samples: {len(df_train)}\")\n",
        "print(f\"Validation Samples: {len(df_val)}\")\n",
        "print(f\"Validation Samples: {len(df_test)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.479548Z",
          "iopub.status.idle": "2025-12-15T17:51:03.479816Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.479688Z",
          "shell.execute_reply": "2025-12-15T17:51:03.4797Z"
        },
        "id": "jbtnctq0m54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#here I will be creating my custom pytorch dataset.\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CelebA_Dataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform = None):\n",
        "        self.img_dir = img_dir\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "        if transform is None:\n",
        "            self.transform = transforms.Compose([\n",
        "                #standard transforms, resizing is for ResNet18.\n",
        "                transforms.Resize((224,224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        img_id = row['image_id']\n",
        "        label = row['Smiling']\n",
        "\n",
        "        img_path = os.path.join(self.img_dir, img_id)\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(image)\n",
        "\n",
        "        return image_tensor, torch.tensor(label, dtype = torch.float32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.480702Z",
          "iopub.status.idle": "2025-12-15T17:51:03.480907Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.480811Z",
          "shell.execute_reply": "2025-12-15T17:51:03.48082Z"
        },
        "id": "imdzoOfUm54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data in batches\n",
        "from torch.utils.data import DataLoader\n",
        "IMG_DIR = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\n",
        "\n",
        "train_dataset = CelebA_Dataset(df_train, IMG_DIR)\n",
        "val_dataset = CelebA_Dataset(df_val, IMG_DIR)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers = NUM_WORKERS,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers = NUM_WORKERS,\n",
        "    shuffle = False\n",
        ")\n",
        "print(\"DataLoaders created. Ready for model setup.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.482089Z",
          "iopub.status.idle": "2025-12-15T17:51:03.482299Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.482197Z",
          "shell.execute_reply": "2025-12-15T17:51:03.482206Z"
        },
        "id": "Oi1Gpze6m54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#defining my model here.\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "\n",
        "#loading the pretrained ResNet18 (on Imagenet)\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "#getting the num of features in the input of last layer of ResNet18's last layer.\n",
        "num_ftrs = model.fc.in_features\n",
        "#modifying the last layer to have only 1 output, this will be the probability.\n",
        "model.fc = nn.Linear(num_ftrs, 1)\n",
        "model = model.to(device)\n",
        "print(f\"ResNet18 model loaded and modified. Final layer output size: {model.fc.out_features}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.482971Z",
          "iopub.status.idle": "2025-12-15T17:51:03.483288Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.48311Z",
          "shell.execute_reply": "2025-12-15T17:51:03.483127Z"
        },
        "id": "oYTDGD2_m54Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#declaring that the loss function, the optimizer is Adam, and the training will continue for\n",
        "#5 epochs.\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
        "NUM_EPOCHS = 5"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.484397Z",
          "iopub.status.idle": "2025-12-15T17:51:03.484698Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.484541Z",
          "shell.execute_reply": "2025-12-15T17:51:03.484554Z"
        },
        "id": "poUdImPbm54Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#here is the training function. since the model is already in Pytorch, it is\n",
        "#very high level and usually simple to implement\n",
        "def train_model(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * inputs.size(0) #batch\n",
        "\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.486004Z",
          "iopub.status.idle": "2025-12-15T17:51:03.486289Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.486123Z",
          "shell.execute_reply": "2025-12-15T17:51:03.486133Z"
        },
        "id": "UwppIxFFm54Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate function. will be using this on val_loader\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            probabilities = torch.sigmoid(outputs).squeeze()\n",
        "            predictions = torch.round(probabilities)\n",
        "\n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.487305Z",
          "iopub.status.idle": "2025-12-15T17:51:03.487538Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.48744Z",
          "shell.execute_reply": "2025-12-15T17:51:03.48745Z"
        },
        "id": "mLfouuLBm54Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0.0\n",
        "\n",
        "#main loop for traububg abd validation.\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
        "    val_accuracy = evaluate_model(model, val_loader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Save the model with the best validation accuracy\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        #saving the weights because kaggle was disconnecting frequently and\n",
        "        #training took some time. so I did not want to lose a high-acc model if I had one\n",
        "        torch.save(model.state_dict(), 'best_classifier.pth')\n",
        "\n",
        "\n",
        "print(f\"Final Validation Accuracy for 'Smiling' Classifier: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.488312Z",
          "iopub.status.idle": "2025-12-15T17:51:03.488627Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.48847Z",
          "shell.execute_reply": "2025-12-15T17:51:03.488484Z"
        },
        "id": "NQAk3Ovmm54Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#helper for getting ResNet-input ready images\n",
        "def get_resnet_transforms():\n",
        "    #this defines the standard ResNet preprocessing (Resize, ToTensor, Normalize)\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "#instantiating\n",
        "resnet_transforms = get_resnet_transforms()\n",
        "\n",
        "\n",
        "#generating 5000 random images for data collection.\n",
        "\n",
        "NUM_SAMPLES = 5000\n",
        "\n",
        "\n",
        "z_vectors = []\n",
        "w_vectors = []\n",
        "labels = []\n",
        "\n",
        "model.eval()\n",
        "G.eval() #models should be in evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(NUM_SAMPLES):\n",
        "        #generating z-space and w-space vectors, similar to before\n",
        "        z = torch.randn([1, G.z_dim], device=device)\n",
        "        w = G.mapping(z, None)\n",
        "\n",
        "        #generating image (StyleGAN output: [1, C, H, W], range [-1, 1])\n",
        "        img_tensor_gan_out = G.synthesis(w, noise_mode='const')\n",
        "\n",
        "\n",
        "        #rescale and convert to NumPy (same logic from Part 1 visualization)\n",
        "        #moving the image to cpu,numpy then transposing and rescaling like before.\n",
        "        img_np = (img_tensor_gan_out.cpu().numpy()[0].transpose(1, 2, 0) * 127.5 + 128).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        #pil image:\n",
        "        image_pil = Image.fromarray(img_np, 'RGB')\n",
        "\n",
        "        #applying transformations to get the image ready to go in ResNet18.\n",
        "        classifier_input = resnet_transforms(image_pil).unsqueeze(0).to(device)\n",
        "        classifier_output = model(classifier_input)\n",
        "\n",
        "        #getting probabilities and predictions\n",
        "        probability = torch.sigmoid(classifier_output).squeeze()\n",
        "        prediction = torch.round(probability).item()\n",
        "\n",
        "        #saving them\n",
        "        z_vectors.append(z.cpu().numpy().flatten())\n",
        "\n",
        "        # Ensure W is 512-dim (using mean if it was broadcast, which is good practice)\n",
        "        if w.dim() == 3 and w.shape[1] > 1:\n",
        "            w_avg = w.mean(dim=1).cpu().numpy().flatten()\n",
        "        else:\n",
        "            w_avg = w.cpu().numpy().flatten()\n",
        "\n",
        "        w_vectors.append(w_avg)\n",
        "        labels.append(prediction)\n",
        "\n",
        "#converting to numpy arrays\n",
        "Z = np.array(z_vectors)\n",
        "W = np.array(w_vectors)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.489896Z",
          "iopub.status.idle": "2025-12-15T17:51:03.490219Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.490046Z",
          "shell.execute_reply": "2025-12-15T17:51:03.490059Z"
        },
        "id": "f8KAxecSm54Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#separating positive and negative indices\n",
        "pos_indices = (Y == 1)\n",
        "neg_indices = (Y == 0)\n",
        "\n",
        "#calculating the direction vector (n) for z-space, using mean difference\n",
        "mu_z_pos = Z[pos_indices].mean(axis = 0)\n",
        "mu_z_neg = Z[neg_indices].mean(axis = 0)\n",
        "n_Z_Mean = mu_z_pos - mu_z_neg\n",
        "#print(f'Z-space mean-diff:\\n {n_Z_Mean}')\n",
        "\n",
        "#calculating the direction vector (n) for w-space, using mean difference\n",
        "mu_w_pos = W[pos_indices].mean(axis = 0)\n",
        "mu_w_neg = W[neg_indices].mean(axis = 0)\n",
        "n_W_Mean = mu_w_pos - mu_w_neg\n",
        "#print(f'\\nW-space mean-diff:\\n {n_W_Mean}')\n",
        "\n",
        "print(\"Mean Difference directions calculated.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.491194Z",
          "iopub.status.idle": "2025-12-15T17:51:03.491513Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.491356Z",
          "shell.execute_reply": "2025-12-15T17:51:03.491369Z"
        },
        "id": "eJJPU3jNm54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#setting c_value small to prevent overfitting\n",
        "C_VALUE = 0.01\n",
        "\n",
        "#fitting logreg to Z-space and have a discriminating boundary line.\n",
        "#the vector perpendicular to this line will be giving the smiling attribute's direction.\n",
        "logreg_Z = LogisticRegression(solver='liblinear', random_state=0, C=C_VALUE)\n",
        "logreg_Z.fit(Z, Y)\n",
        "#the coefficient array (coef_) holds the normal vector to the boundary\n",
        "n_Z_LogReg = logreg_Z.coef_[0]\n",
        "\n",
        "#the same thing but for W-space.\n",
        "logreg_W = LogisticRegression(solver='liblinear', random_state=0, C=C_VALUE)\n",
        "logreg_W.fit(W, Y)\n",
        "n_W_LogReg = logreg_W.coef_[0]\n",
        "\n",
        "print(\"Logistic Regression directions calculated.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.492329Z",
          "iopub.status.idle": "2025-12-15T17:51:03.492637Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.492486Z",
          "shell.execute_reply": "2025-12-15T17:51:03.492501Z"
        },
        "id": "RJUtbDywm54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to manipulate an image constrained to the given parameters.\n",
        "def generate_manipulated_image(v_old, n, alpha, is_w_space, G, device):\n",
        "\n",
        "    #this is the given formula for manipulation.\n",
        "    v_new_np = v_old + alpha * n\n",
        "\n",
        "    # Convert to PyTorch tensor and move to device\n",
        "    # The unsqueeze(0) makes it [1, 512]\n",
        "    v_new = torch.from_numpy(v_new_np).float().unsqueeze(0).to(device)\n",
        "\n",
        "    # 2. Prepare the W-space tensor (w_new)\n",
        "    if not is_w_space:\n",
        "        #if starting in Z-space, map to W-space. Output w_new is [1, 18, 512] (3D)\n",
        "        w_new = G.mapping(v_new, None)\n",
        "    else:\n",
        "        #copy-paste from Gemini here. That is because the layers got me confused.\n",
        "        # If starting in W-space (v_new is [1, 512]), it must be repeated for the synthesis network.\n",
        "        # G.num_ws is the number of layers (typically 18).\n",
        "\n",
        "        # We need to reshape v_new from [1, 512] to [1, Num_Layers, 512]\n",
        "        num_layers = G.num_ws if hasattr(G, 'num_ws') else G.mapping.num_ws\n",
        "\n",
        "        # Use .repeat() to broadcast the single W vector across all layers\n",
        "        w_new = v_new.unsqueeze(1).repeat(1, num_layers, 1) # Shape: [1, 18, 512] (3D)\n",
        "\n",
        "    #generating the image using w_new\n",
        "    img_tensor = G.synthesis(w_new, noise_mode='const')\n",
        "\n",
        "    #moving image to cpu,numpy, transpose and rescale as before. maybe should have\n",
        "    #used another helper for this.\n",
        "    img_np = (img_tensor.cpu().numpy()[0].transpose(1, 2, 0) * 127.5 + 128).clip(0, 255).astype(np.uint8)\n",
        "    image = Image.fromarray(img_np, 'RGB')\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.495006Z",
          "iopub.status.idle": "2025-12-15T17:51:03.495721Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.495553Z",
          "shell.execute_reply": "2025-12-15T17:51:03.495568Z"
        },
        "id": "BQdxZDNUm54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "#as instructed, choosing a seed here.\n",
        "SEED = 2020205172\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "#generating initial latent vectors (z and w)\n",
        "with torch.no_grad():\n",
        "    #z_old: The starting vector in Z-space\n",
        "    z_old_tensor = torch.randn([1, G.z_dim], device=device)\n",
        "\n",
        "    #w_old: The corresponding vector in W-space (output of the mapping network)\n",
        "    w_old_tensor = G.mapping(z_old_tensor, None)\n",
        "\n",
        "#convert to 512-D NumPy arrays for the manipulation formula\n",
        "z_old_np = z_old_tensor.cpu().numpy().flatten()\n",
        "#use the average W vector if it's layered, otherwise flatten the single vector\n",
        "if w_old_tensor.dim() == 3 and w_old_tensor.shape[1] > 1:\n",
        "    w_old_np = w_old_tensor.mean(dim=1).cpu().numpy().flatten()\n",
        "else:\n",
        "    w_old_np = w_old_tensor.cpu().numpy().flatten()\n",
        "\n",
        "#generating and displaying the \"original\" image for this seed.\n",
        "original_image = generate_manipulated_image(z_old_np, np.zeros_like(z_old_np), 0, False, G, device)\n",
        "original_image.save('0_Original_Image.png')\n",
        "print(\"Original Image Generated (Original_Image.png)\")\n",
        "display(original_image)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.496475Z",
          "iopub.status.idle": "2025-12-15T17:51:03.496767Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.496616Z",
          "shell.execute_reply": "2025-12-15T17:51:03.49663Z"
        },
        "id": "7KBhKJaGm54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization helper\n",
        "def normalize_vector(n):\n",
        "    return n / np.linalg.norm(n)\n",
        "\n",
        "n_Z_LogReg = normalize_vector(n_Z_LogReg)\n",
        "n_W_LogReg = normalize_vector(n_W_LogReg)\n",
        "n_Z_Mean = normalize_vector(n_Z_Mean)\n",
        "n_W_Mean = normalize_vector(n_W_Mean)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.497883Z",
          "iopub.status.idle": "2025-12-15T17:51:03.498111Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.497997Z",
          "shell.execute_reply": "2025-12-15T17:51:03.498009Z"
        },
        "id": "Fyf_nExEm54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA = 3\n",
        "\n",
        "print(\"Experiment 1: Z-space vs W-space\")\n",
        "\n",
        "#manipulation using z-space logreg direction\n",
        "z_image = generate_manipulated_image(\n",
        "    v_old = z_old_np,\n",
        "    n = n_Z_LogReg,\n",
        "    alpha = ALPHA,\n",
        "    is_w_space = False,\n",
        "    G = G,\n",
        "    device = device\n",
        ")\n",
        "z_image.save('1_Z_LogReg_Manipulated.png')\n",
        "print(f\"Z-Space Image (LogReg, alpha={ALPHA}) saved.\")\n",
        "\n",
        "#manipulation using w-space logreg direction\n",
        "w_image = generate_manipulated_image(\n",
        "    v_old = w_old_np,\n",
        "    n = n_W_LogReg,\n",
        "    alpha = ALPHA,\n",
        "    is_w_space = True,\n",
        "    G = G,\n",
        "    device = device\n",
        ")\n",
        "w_image.save('2_W_LogReg_Manipulated.png')\n",
        "print(f\"W-Space Image (LogReg, alpha={ALPHA}) saved.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.498913Z",
          "iopub.status.idle": "2025-12-15T17:51:03.499199Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.499044Z",
          "shell.execute_reply": "2025-12-15T17:51:03.499059Z"
        },
        "id": "RfLHQV0Om54a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(display(original_image))\n",
        "print(display(z_image))\n",
        "print(display(w_image))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.500412Z",
          "iopub.status.idle": "2025-12-15T17:51:03.500911Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.500714Z",
          "shell.execute_reply": "2025-12-15T17:51:03.50073Z"
        },
        "id": "tYVoU6jQm54b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, w-space transformation preserved the attributes other than smiling better than z-space transformation. Also, smiling is more apparent in w-space transform.\n",
        "\n",
        "One important note is, in the first place I tried to do this comparison without normalizing the vectors n_Z_LogReg and n_W_LogReg. The results were the other way around, w-space transformations would look like mud. That is probably because the w-vector is larger than z-vector numerically, so even with a small alpha the photo gets rubbish."
      ],
      "metadata": {
        "id": "SYc5B9sym54b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA = 3\n",
        "\n",
        "print(\"\\n--- Experiment 2: MEAN VS SVM(LOGREG) ---\")\n",
        "\n",
        "#manipulation using w-space mean-diff direction\n",
        "w_image1 = generate_manipulated_image(\n",
        "    v_old = w_old_np,\n",
        "    n = n_W_Mean,\n",
        "    alpha = ALPHA,\n",
        "    is_w_space = True,\n",
        "    G = G,\n",
        "    device = device\n",
        ")\n",
        "w_image1.save('1_W_Mean_Manipulated.png')\n",
        "print(f\"Z-Space Image (LogReg, alpha={ALPHA}) saved.\")\n",
        "\n",
        "#manipulation using w-space logreg direction\n",
        "w_image2 = generate_manipulated_image(\n",
        "    v_old = w_old_np,\n",
        "    n = n_W_LogReg,\n",
        "    alpha = ALPHA,\n",
        "    is_w_space = True,\n",
        "    G = G,\n",
        "    device = device\n",
        ")\n",
        "w_image2.save('22_W_LogReg_Manipulated.png')\n",
        "print(f\"W-Space Image (LogReg, alpha={ALPHA}) saved.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:03.502699Z",
          "iopub.status.idle": "2025-12-15T17:51:03.503006Z",
          "shell.execute_reply.started": "2025-12-15T17:51:03.502853Z",
          "shell.execute_reply": "2025-12-15T17:51:03.502866Z"
        },
        "id": "Yque-_Ypm54b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(display(original_image))\n",
        "print(display(w_image1))\n",
        "print(display(w_image2))"
      ],
      "metadata": {
        "trusted": true,
        "id": "T0SIr3nSm54b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA_VALUES = [-8.0, -5.0, -2.0, 0.0, 2.0, 5.0, 8]\n",
        "\n",
        "\n",
        "print(\"Experiment 3: Alpha Scaling\")\n",
        "\n",
        "for alpha in ALPHA_VALUES:\n",
        "    #manipulation using w-space logreg direction\n",
        "    image = generate_manipulated_image(\n",
        "        v_old = w_old_np,\n",
        "        n = n_W_LogReg, # Use the normalized LogReg vector\n",
        "        alpha = alpha,\n",
        "        is_w_space = True,\n",
        "        G = G,\n",
        "        device = device\n",
        "    )\n",
        "    filename = f'4_W_LogReg_Alpha_{alpha:.1f}.png'\n",
        "    image.save(filename)\n",
        "    print(f\"Image for alpha={alpha:.1f} saved as {filename}\")\n",
        "    display(image)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-15T17:51:09.159785Z",
          "iopub.execute_input": "2025-12-15T17:51:09.160432Z",
          "iopub.status.idle": "2025-12-15T17:51:14.166597Z",
          "shell.execute_reply.started": "2025-12-15T17:51:09.160409Z",
          "shell.execute_reply": "2025-12-15T17:51:14.16569Z"
        },
        "id": "OrQwb63em54b"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}